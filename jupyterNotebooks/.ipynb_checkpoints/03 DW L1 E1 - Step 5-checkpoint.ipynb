{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 5: ETL the data from 3NF tables to Facts & Dimension Tables\n",
    "**IMPORTANT:** The following exercise depends on first having successing completed Exercise 1: Step 4. \n",
    "\n",
    "Start by running the code in the cell below to connect to the database. If you are coming back to this exercise, then uncomment and run the first cell to recreate the database. If you recently completed steps 1 through 4, then skip to the second cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !PGPASSWORD=student createdb -h 127.0.0.1 -U student pagila\n",
    "# !PGPASSWORD=student psql -q -h 127.0.0.1 -U student -d pagila -f Data/pagila-schema.sql\n",
    "# !PGPASSWORD=student psql -q -h 127.0.0.1 -U student -d pagila -f Data/pagila-data.sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sql extension is already loaded. To reload it, use:\n",
      "  %reload_ext sql\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Connected: postgres@pagila'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext sql\n",
    "\n",
    "DB_ENDPOINT = os.environ[\"PGHOST\"]\n",
    "DB = 'pagila'\n",
    "DB_USER = os.environ[\"PGUSER\"]\n",
    "DB_PASSWORD = os.environ[\"PGPASSWORD\"]\n",
    "DB_PORT = os.environ[\"PGPORT\"]\n",
    "\n",
    "# postgresql://username:password@host:port/database\n",
    "conn_string = \"postgresql://{}:{}@{}:{}/{}\" \\\n",
    "                        .format(DB_USER, DB_PASSWORD, DB_ENDPOINT, DB_PORT, DB)\n",
    "\n",
    "# print(conn_string)\n",
    "%sql $conn_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing SQL to SQL ETL\n",
    "When writing SQL to SQL ETL, you first create a table then use the INSERT and SELECT statements together to populate the table. Here's a simple example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you create a table called test_table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://postgres:***@localhost:5432/pagila\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "CREATE TABLE test_table\n",
    "(\n",
    "  date timestamp,\n",
    "  revenue  decimal(5,2)\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you use the INSERT and SELECT statements to populate the table. In this case, the SELECT statement extracts data from the `payment` table and INSERTs it INTO the `test_table`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://postgres:***@localhost:5432/pagila\n",
      "16049 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "INSERT INTO test_table (date, revenue)\n",
    "SELECT payment_date AS date,\n",
    "       amount AS revenue\n",
    "FROM payment;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you can use a SELECT statement to take a look at your new table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://postgres:***@localhost:5432/pagila\n",
      "5 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>date</th>\n",
       "        <th>revenue</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2017-01-24 21:40:19.996577</td>\n",
       "        <td>1.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2017-01-25 15:16:50.996577</td>\n",
       "        <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2017-01-28 21:44:14.996577</td>\n",
       "        <td>6.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2017-01-29 00:58:02.996577</td>\n",
       "        <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2017-01-29 08:10:06.996577</td>\n",
       "        <td>4.99</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(datetime.datetime(2017, 1, 24, 21, 40, 19, 996577), Decimal('1.99')),\n",
       " (datetime.datetime(2017, 1, 25, 15, 16, 50, 996577), Decimal('0.99')),\n",
       " (datetime.datetime(2017, 1, 28, 21, 44, 14, 996577), Decimal('6.99')),\n",
       " (datetime.datetime(2017, 1, 29, 0, 58, 2, 996577), Decimal('0.99')),\n",
       " (datetime.datetime(2017, 1, 29, 8, 10, 6, 996577), Decimal('4.99'))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT * FROM test_table LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to delete the table and start over, use the DROP TABLE command, like below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://postgres:***@localhost:5432/pagila\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql DROP TABLE test_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now you'll do the same thing below to create the dimension and fact tables for the Star Schema using the data in the 3NF database.\n",
    "\n",
    "## ETL from 3NF to Star Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3NF - Entity Relationship Diagram\n",
    "\n",
    "<img src=\"./pagila-3nf.png\" width=\"50%\"/>\n",
    "\n",
    "### Star Schema - Entity Relationship Diagram\n",
    "\n",
    "<img src=\"pagila-star.png\" width=\"50%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you'll populate the tables in the Star schema. You'll `extract` data from the normalized database, `transform` it, and `load` it into the new tables. \n",
    "\n",
    "To serve as an example, below is the query that populates the `dimDate` table with data from the `payment` table.\n",
    "* NOTE 1: The EXTRACT function extracts date parts from the payment_date variable.\n",
    "* NOTE 2: If you get an error that says that the `dimDate` table doesn't exist, then go back to Exercise 1: Step 4 and recreate the tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://postgres:***@localhost:5432/pagila\n",
      "40 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "INSERT INTO star.dim_date (\n",
    "     date_key\n",
    "    ,date, year\n",
    "    ,quarter\n",
    "    ,month\n",
    "    ,day\n",
    "    ,week\n",
    "    ,is_weekend\n",
    ")\n",
    "\n",
    "SELECT DISTINCT\n",
    "     (TO_CHAR(payment_date::DATE, 'yyyyMMDD')::integer) AS date_key\n",
    "    ,date(payment_date) AS date\n",
    "    ,EXTRACT(year FROM payment_date) AS year\n",
    "    ,EXTRACT(quarter FROM payment_date) AS quarter\n",
    "    ,EXTRACT(month FROM payment_date) AS month\n",
    "    ,EXTRACT(day FROM payment_date) AS day\n",
    "    ,EXTRACT(week FROM payment_date) AS week\n",
    "    ,CASE\n",
    "        WHEN EXTRACT(ISODOW FROM payment_date) IN (6, 7)\n",
    "        THEN true\n",
    "        ELSE false\n",
    "    END AS is_weekend\n",
    "    \n",
    "FROM\n",
    "    payment\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Now it's your turn. Populate the `dimCustomer` table with data from the `customer`, `address`, `city`, and `country` tables. Use the starter code as a guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://postgres:***@localhost:5432/pagila\n",
      "599 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "INSERT INTO\n",
    "    star.dim_customer (\n",
    "         customer_id --customer\n",
    "        ,first_name --customer\n",
    "        ,last_name --customer\n",
    "        ,email --customer\n",
    "        ,address --address\n",
    "        ,address2 --address\n",
    "        ,district --address\n",
    "        ,city --city\n",
    "        ,country --country\n",
    "        ,postal_code --address\n",
    "        ,phone --address\n",
    "        ,active --customer\n",
    "        ,create_date --customer\n",
    "        ,start_date\n",
    "        ,end_date\n",
    "    )\n",
    "    \n",
    "SELECT\n",
    "     customer.customer_id\n",
    "    ,INITCAP(customer.first_name)\n",
    "    ,INITCAP(customer.last_name)\n",
    "    ,LOWER(customer.email)\n",
    "    ,address.address\n",
    "    ,address.address2\n",
    "    ,address.district\n",
    "    ,city.city\n",
    "    ,country.country\n",
    "    ,address.postal_code\n",
    "    ,address.phone\n",
    "    ,customer.active\n",
    "    ,customer.create_date\n",
    "    ,now() AS start_date\n",
    "    ,'99991231' AS end_date\n",
    "    \n",
    "FROM\n",
    "    customer\n",
    "INNER JOIN\n",
    "    address\n",
    "ON\n",
    "    customer.address_id = address.address_id\n",
    "INNER JOIN\n",
    "    city\n",
    "ON\n",
    "    address.city_id = city.city_id\n",
    "INNER JOIN\n",
    "    country \n",
    "ON\n",
    "    city.country_id = country.country_id\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Populate the `dimMovie` table with data from the `film` and `language` tables. Use the starter code as a guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://postgres:***@localhost:5432/pagila\n",
      "1000 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "INSERT INTO\n",
    "    star.dim_movie (\n",
    "         film_id --film\n",
    "        ,title --film\n",
    "        ,description --film\n",
    "        ,release_year --film\n",
    "        ,language --language\n",
    "        ,original_language --language\n",
    "        ,rental_duration --film\n",
    "        ,length --film\n",
    "        ,rating --film\n",
    "        ,special_features --film\n",
    "    )\n",
    "    \n",
    "SELECT\n",
    "     film.film_id\n",
    "    ,INITCAP(film.title)\n",
    "    ,film.description\n",
    "    ,film.release_year\n",
    "    ,language.name\n",
    "    ,orig_lang.name\n",
    "    ,film.rental_duration\n",
    "    ,film.length\n",
    "    ,film.rating\n",
    "    ,film.special_features\n",
    "    \n",
    "FROM\n",
    "    film\n",
    "INNER JOIN\n",
    "    language\n",
    "ON\n",
    "    film.language_id = language.language_id\n",
    "LEFT JOIN\n",
    "    language orig_lang\n",
    "ON\n",
    "    film.original_language_id = orig_lang.language_id\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Populate the `dimStore` table with data from the `store`, `staff`, `address`, `city`, and `country` tables. This time, there's no guide. You should write the query from scratch. Use the previous queries as a reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://postgres:***@localhost:5432/pagila\n",
      "2 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "INSERT INTO\n",
    "    star.dim_store (\n",
    "         store_id --store\n",
    "        ,address --address\n",
    "        ,address2 --address\n",
    "        ,district --address\n",
    "        ,city --city\n",
    "        ,country --country\n",
    "        ,postal_code --address\n",
    "        ,manager_first_name --staff\n",
    "        ,manager_last_name --staff\n",
    "        ,start_date --calculated\n",
    "        ,end_date --calculated\n",
    "    )\n",
    "    \n",
    "SELECT\n",
    "     store.store_id\n",
    "    ,address.address\n",
    "    ,address.address2\n",
    "    ,address.district\n",
    "    ,city.city\n",
    "    ,country.country\n",
    "    ,address.postal_code\n",
    "    ,staff.first_name\n",
    "    ,staff.last_name\n",
    "    ,CURRENT_DATE AS start_date\n",
    "    ,'99991231' AS end_date\n",
    "\n",
    "FROM\n",
    "   store\n",
    "INNER JOIN\n",
    "    staff\n",
    "ON\n",
    "    store.manager_staff_id = staff.staff_id\n",
    "INNER JOIN\n",
    "    address\n",
    "ON\n",
    "    store.address_id = address.address_id\n",
    "INNER JOIN\n",
    "    city\n",
    "ON\n",
    "    address.city_id = city.city_id\n",
    "INNER JOIN\n",
    "    country\n",
    "ON\n",
    "    city.country_id = country.country_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Populate the `factSales` table with data from the `payment`, `rental`, and `inventory` tables. This time, there's no guide. You should write the query from scratch. Use the previous queries as a reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://postgres:***@localhost:5432/pagila\n",
      "16049 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "INSERT INTO\n",
    "    star.fact_sales (\n",
    "         date_key --dim_date\n",
    "        ,customer_key --dim_customer\n",
    "        ,movie_key --dim_movie\n",
    "        ,store_key --dim_store\n",
    "        ,sales_amount --payment\n",
    "    )\n",
    "    \n",
    "SELECT\n",
    "     dim_date.date_key\n",
    "    ,dim_customer.customer_key\n",
    "    ,dim_movie.movie_key\n",
    "    ,dim_store.store_key\n",
    "    ,payment.amount\n",
    "    \n",
    "FROM\n",
    "    public.payment AS payment\n",
    "    \n",
    "-- film_id\n",
    "INNER JOIN\n",
    "    public.rental AS rental\n",
    "ON\n",
    "    payment.rental_id = rental.rental_id\n",
    "INNER JOIN\n",
    "    public.inventory AS inventory\n",
    "ON\n",
    "    inventory.inventory_id = rental.inventory_id\n",
    "INNER JOIN\n",
    "    star.dim_movie AS dim_movie\n",
    "ON\n",
    "    dim_movie.film_id = inventory.film_id\n",
    "    \n",
    "-- store_id\n",
    "INNER JOIN\n",
    "    star.dim_store AS dim_store\n",
    "ON\n",
    "    inventory.store_id = dim_store.store_id\n",
    "    \n",
    "LEFT JOIN\n",
    "    star.dim_date AS dim_date\n",
    "ON\n",
    "    payment.payment_date::DATE = dim_date.date\n",
    "LEFT JOIN\n",
    "    star.dim_customer AS dim_customer\n",
    "ON\n",
    "    payment.customer_id = dim_customer.customer_id\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
